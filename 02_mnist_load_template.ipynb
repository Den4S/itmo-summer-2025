{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35c58e4e-9226-4d24-ae10-b84c5cc05ce5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a31da-c6c3-427d-a070-afdc48a01305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f6378-5bc3-477d-bfd3-a08a9123b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f309cc84-f338-409f-b1a3-6ac36b945622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39328b9-9fa8-4937-9a53-905ea59276c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59041be7-8d30-4981-a3da-e5d090a32339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e92418-e8e7-4baa-882f-92b87f2c68ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba00109-7b62-4f32-b685-17f437630230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import InterpolationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8603ed7b-af59-4d79-b6a7-dcb599e28e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b216854c-ca48-43e5-8672-070d0ac78392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02414ffa-fc8b-4cd7-a6fa-1f744a9a68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a1d315-3dad-4b75-9595-de862888c419",
   "metadata": {},
   "source": [
    "#### `svetlanna`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d7937-25cf-465f-af73-90f208686d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna.units import ureg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902804f6-c104-4b4b-9b9f-f43ac9b4c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna import SimulationParameters\n",
    "from svetlanna.parameters import ConstrainedParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7826e8-9de7-4539-b16a-60827a25959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna import Wavefront\n",
    "from svetlanna.transforms import ToWavefront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a64cdd-5ed6-4fe1-ab77-d95120a45f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna.elements import FreeSpace, Aperture, RectangularAperture, DiffractiveLayer\n",
    "from svetlanna.setup import LinearOpticalSetup\n",
    "from svetlanna.detector import Detector, DetectorProcessorClf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3be29-791b-48a3-946b-b300ea0e26e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna.visualization import show_stepwise_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d898096-f89a-4bb4-8bd2-b11d3b044c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna.clerk import Clerk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73440a60-e88a-49d7-81a2-d6a3bed3bf63",
   "metadata": {},
   "source": [
    "#### `src`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc8319-2f82-4979-889a-4efcc8466039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset of wavefronts\n",
    "from src.wf_datasets import DatasetOfWavefronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688215a7-800b-4108-aaa6-807f98b1b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and evaluation loops\n",
    "from src.clf_loops import onn_train_clf, onn_validate_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dfb2cb-94cf-4e83-a079-0a6ec828a66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cea815ac-b473-4d58-a0d5-1253d9740a40",
   "metadata": {},
   "source": [
    "# Optical Neural Network\n",
    "\n",
    "In that example notebook we will try to realize a simple architecture of an optical neural network from the article [[1]](https://www.science.org/doi/10.1126/science.aat8084)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a43dea1-d35e-4916-9e97-b342a987d363",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Select the folder with results to load (TODO) </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6532e15d-291a-4c30-9310-90f6bc4663c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all saved models\n",
    "\n",
    "DIR_RESULTS = 'results'\n",
    "\n",
    "filepathes = []\n",
    "\n",
    "for file in os.listdir(DIR_RESULTS):      \n",
    "    filename = os.fsdecode(file)\n",
    "    if os.path.isdir(os.path.join(DIR_RESULTS, filename)):\n",
    "        filepathes.append(filename)\n",
    "\n",
    "print(*sorted(filepathes), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5892df30-d236-4eb9-bb4e-e106b68d41b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_EXP = 'exp_20-06-2025_14-48'  # TODO: select experiment folder from the list above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6182a7-efd9-49d7-9d50-e26cdb7802b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FOLDER = f'{DIR_RESULTS}/{SELECTED_EXP}'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc50be-7aed-4744-a7a0-328283ba11cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{RESULTS_FOLDER}/conditions.json') as json_file:\n",
    "    LOADED_VARIABLES = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167255e4-2eac-45d4-954f-9aebc1b14f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOADED_VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a46e5e-6053-4e74-93eb-fb8e2c8f45a0",
   "metadata": {},
   "source": [
    "# 1. Simulation parameters\n",
    "\n",
    "\n",
    "First of all we need to specify simulation parameters for our task: they includes wavelength $\\lambda$ and a numerical mesh (in our case it corresponds to a neuron size).\n",
    "\n",
    "**<span style=\"color:red\">Sources to use:</span>**\n",
    "[[1]](https://www.science.org/doi/10.1126/science.aat8084) and its [Supplementary Material](https://www.science.org/doi/suppl/10.1126/science.aat8084/suppl_file/aat8084-lin-sm-rev-3.pdf), [[2]](https://ieeexplore.ieee.org/abstract/document/8732486) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d815d886-8ffb-4a79-b488-6b207cd05b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_const = 299_792_458  # [m / s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e389f46c-f2ca-4204-a30f-c270e5987163",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_wavelength = LOADED_VARIABLES['wavelength']  # [m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257fcf62-f897-4b81-af45-96326d47ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron size (square)\n",
    "neuron_size = LOADED_VARIABLES['neuron_size']  # [m]\n",
    "NEURON_SIZE = neuron_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dc8771-a0e3-418b-9c0d-a725b21d12c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Specified parameters:')\n",
    "# uncomment next two lines!\n",
    "print(f'lambda = {working_wavelength * 1e6:.3f} um')\n",
    "print(f'neuron size = {neuron_size * 1e6:.3f} um')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6618b4ec-9fe2-45c7-8019-1f3b63c2e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an actual zone where weights will be updated during a training process\n",
    "ALL_SIZE = LOADED_VARIABLES['mesh_size']  # for example (100, 100) neurons\n",
    "USE_APERTURES = LOADED_VARIABLES['use_apertures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb111990-529e-4153-b585-ab0127bfc99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_APERTURES:\n",
    "    # if we will add apertures we must specify the aperture size here!\n",
    "    DETECTOR_SIZE = LOADED_VARIABLES['aperture_size']\n",
    "else:\n",
    "    DETECTOR_SIZE = ALL_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da8d905-67e4-4df9-8686-ce14f1b71b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of neurons in simulation\n",
    "x_layer_nodes = ALL_SIZE[1]\n",
    "y_layer_nodes = ALL_SIZE[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d7f13-d150-48be-8e4c-c97ea588ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate physical size of each layer in [m]\n",
    "x_layer_size_m = x_layer_nodes * neuron_size  # [m]\n",
    "y_layer_size_m = y_layer_nodes * neuron_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37057e7b-8ba8-49d4-a9e3-c4b9ece0c7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Layer size (in neurons): {x_layer_nodes} x {y_layer_nodes} = {x_layer_nodes * y_layer_nodes}')\n",
    "print(f'Layer size (in cm): {x_layer_size_m * 1e2} x {y_layer_size_m * 1e2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d64da3-9611-4b74-84d0-a706f2c2e3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d95cc-633a-481a-bfa6-fe25a1d5b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation parameters for the rest of the notebook!\n",
    "\n",
    "SIM_PARAMS = SimulationParameters(\n",
    "    axes={\n",
    "        'W': torch.linspace(-x_layer_size_m / 2, x_layer_size_m / 2, x_layer_nodes),\n",
    "        'H': torch.linspace(-y_layer_size_m / 2, y_layer_size_m / 2, y_layer_nodes),\n",
    "        'wavelength': working_wavelength,  # monochromatic!\n",
    "    }\n",
    ")  # this is a custom object from our library `svetlanna`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d6f07c-1cb7-4b52-87c8-7c5306df2a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddbc9f3f-308d-4c58-b79c-de72e1eeff7b",
   "metadata": {},
   "source": [
    "# 2. Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18398b5-9ee7-470c-b2ef-bcd15b6f4768",
   "metadata": {},
   "source": [
    "## 2.1. [MNIST Dataset](https://www.kaggle.com/datasets/hojjatk/mnist-dataset)\n",
    "\n",
    "Here we load dataset of images but we need to transform them to Wavefronts in order to use them for DNN training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de278d4-1f7a-4651-8fce-74c41567c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a directory for a dataset\n",
    "MNIST_DATA_FOLDER = './data'  # folder to store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d740b2-dfd1-4bf3-a86c-6fb13a831df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN (images)\n",
    "mnist_train_ds = torchvision.datasets.MNIST(\n",
    "    root=MNIST_DATA_FOLDER,\n",
    "    train=True,  # for train dataset\n",
    "    download=True,\n",
    ")\n",
    "# TEST (images)\n",
    "mnist_test_ds = torchvision.datasets.MNIST(\n",
    "    root=MNIST_DATA_FOLDER,\n",
    "    train=False,  # for test dataset\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fb6dc4-3849-467c-957d-26617d8c5214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "208ca22f-13b4-4066-a850-1bd35776637b",
   "metadata": {},
   "source": [
    "## 2.2. Create Train and Test datasets of wavefronts\n",
    "\n",
    "From [[2]](https://ieeexplore.ieee.org/abstract/document/8732486):\n",
    "\n",
    "> Input objects were encoded in amplitude channel (MNIST) of the input plane and were illuminated with a uniform plane wave at a wavelength of $\\lambda$ to match the conditions introduced in [[1]](https://www.science.org/doi/10.1126/science.aat8084) for all-optical classification.\n",
    "\n",
    "So, we need to do an amplitude modulation of each image from the dataset!\n",
    "\n",
    "**<span style=\"color:red\">Comment:</span>**\n",
    "We will see later what does \"amplitude modulation\" mean!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c37007c-0731-4b58-9059-e2f2bb792b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select modulation type\n",
    "MODULATION_TYPE = 'amp'  # using ONLY amplitude to encode each picture in a Wavefront!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6297fd51-0bec-4b90-bf86-0346bc460f2e",
   "metadata": {},
   "source": [
    "### 2.2.1. Transformations of images to Wavefronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88113581-f819-4554-8d6a-db075f713a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_y = int(DETECTOR_SIZE[0] / 2)\n",
    "resize_x = int(DETECTOR_SIZE[1] / 2)  # shape for transforms.Resize\n",
    "\n",
    "# paddings along OY\n",
    "pad_top = int((y_layer_nodes - resize_y) / 2)\n",
    "pad_bottom = y_layer_nodes - pad_top - resize_y\n",
    "# paddings along OX\n",
    "pad_left = int((x_layer_nodes - resize_x) / 2)\n",
    "pad_right = x_layer_nodes - pad_left - resize_x  # params for transforms.Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e20e55-53f7-4f92-95eb-3ef75d5dddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose all transforms!\n",
    "image_transform_for_ds = transforms.Compose(\n",
    "  [\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Resize(\n",
    "          size=(resize_y, resize_x),\n",
    "          interpolation=InterpolationMode.NEAREST,\n",
    "      ),\n",
    "      transforms.Pad(\n",
    "          padding=(\n",
    "              pad_left,  # left padding\n",
    "              pad_top,  # top padding\n",
    "              pad_right,  # right padding\n",
    "              pad_bottom  # bottom padding\n",
    "          ),\n",
    "          fill=0,\n",
    "      ),  # padding to match sizes!\n",
    "      ToWavefront(modulation_type=MODULATION_TYPE)  # <- select modulation type!!!\n",
    "  ]  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb08e9c-26e0-4241-b2b0-88ea4529e96b",
   "metadata": {},
   "source": [
    "### 2.2.2. Create Dataset objects for train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7309365a-2986-45e8-a259-97f378fcccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN dataset of WAVEFRONTS\n",
    "mnist_wf_train_ds = DatasetOfWavefronts(\n",
    "    init_ds=mnist_train_ds,  # dataset of images\n",
    "    transformations=image_transform_for_ds,  # image transformation\n",
    "    sim_params=SIM_PARAMS,  # simulation parameters\n",
    ")\n",
    "# TEST dataset of WAVEFRONTS\n",
    "mnist_wf_test_ds = DatasetOfWavefronts(\n",
    "    init_ds=mnist_test_ds,  # dataset of images\n",
    "    transformations=image_transform_for_ds,  # image transformation\n",
    "    sim_params=SIM_PARAMS,  # simulation parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b39769-edd7-4085-bb46-cc79dd86029d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73ae7308-f611-4948-a9fd-afa66856dc09",
   "metadata": {},
   "source": [
    "# 3. Optical network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72dbe6a-b8f5-42cd-9852-74f27fbe23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_DIFF_LAYERS = LOADED_VARIABLES['num_diff_layers']  # number of diffractive layers\n",
    "FREE_SPACE_DISTANCE = LOADED_VARIABLES['free_space_distance']  # [m] - distance between difractive layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de30d8bb-2854-4726-9757-e02fd1ed123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Distance between layers is {FREE_SPACE_DISTANCE * 1e2:.3f} cm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "628a0c01-5dc2-46cb-9ee3-b6d1c0acaa26",
   "metadata": {},
   "source": [
    "## 3.1. Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c017b60c-cb2c-4707-800e-5dfd2770389c",
   "metadata": {},
   "source": [
    "### 3.1.1. Elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572433d3-ddab-40ec-9fbf-974e0150f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PHASE = 2 * np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e45194-9345-4287-af3e-27f8ebf6f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREESPACE_METHOD = 'AS'  # we use an angular spectrum method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd8c37-cf07-4272-b2d5-b6b830ccc927",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_PHASES = torch.ones(NUM_OF_DIFF_LAYERS) * np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c8eff4-fd1a-41f2-b5df-056ff54edc2a",
   "metadata": {},
   "source": [
    "#### Functions that return single elements for further architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22411824-c546-4721-99cb-1564445a4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKE A LOOK! CODE HERE IS READY\n",
    "def get_const_phase_layer(\n",
    "    sim_params: SimulationParameters,\n",
    "    value: float, \n",
    "    max_phase=2 * torch.pi\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns DiffractiveLayer with a constant phase mask.\n",
    "    \"\"\"\n",
    "    x_nodes, y_nodes = sim_params.axes_size(axs=('W', 'H'))\n",
    "\n",
    "    const_mask = torch.ones(size=(y_nodes, x_nodes)) * value\n",
    "    \n",
    "    return DiffractiveLayer(\n",
    "        simulation_parameters=sim_params,\n",
    "        mask=ConstrainedParameter(\n",
    "            const_mask,\n",
    "            min_value=0,\n",
    "            max_value=max_phase\n",
    "        ),  # HERE WE ARE USING CONSTRAINED PARAMETER! Phases are learnable!\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b103a40-895b-4915-bdb8-01cab2838c1d",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">3.1.2. List of Elements (!TODO!)</span>\n",
    "\n",
    "Function to construct a list of elements to reproduce an architecture from [the extended article](https://ieeexplore.ieee.org/abstract/document/8732486):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df37b226-fae8-4c79-a045-ba36c1c200a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: copy your function!!! or add it to src/ folder as a script and import the function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e3cf49-5e7f-4fe1-81c9-dd90021c9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elements_list(\n",
    "    num_layers,\n",
    "    simulation_parameters,\n",
    "    freespace_method,\n",
    "    phase_values,\n",
    "    apertures=False,\n",
    "    aperture_size=(100, 100)\n",
    "):\n",
    "    # TODO: Copy your function!\n",
    "\n",
    "    return elements_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b12dba0-f5fb-461f-b724-a9ea57895765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f0c4c-6b3a-4d43-815e-eefc747922b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_elements_list = get_elements_list(\n",
    "    num_layers=NUM_OF_DIFF_LAYERS,\n",
    "    simulation_parameters=SIM_PARAMS,\n",
    "    freespace_method=FREESPACE_METHOD,\n",
    "    phase_values=INIT_PHASES,\n",
    "    apertures=USE_APERTURES,\n",
    "    aperture_size=DETECTOR_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2006774-6cd7-4c26-ac94-ea6ca05214b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of elements in the system (including Detector): {len(architecture_elements_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a34cf91-1e75-4b23-a7d4-84ca094f0529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61958d45-f06e-4292-be5e-e0025dd1b2db",
   "metadata": {},
   "source": [
    "### 3.1.3. Compose `LinearOpticalSetup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727a9d29-8b31-47e9-b0b0-fdae9d44c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_setup(simulation_parameters, apertures=False):\n",
    "    \"\"\"\n",
    "    Returns an optical setup. Recreates all elements.\n",
    "    \"\"\"\n",
    "    elements_list = get_elements_list(\n",
    "        num_layers=NUM_OF_DIFF_LAYERS,\n",
    "        simulation_parameters=SIM_PARAMS,\n",
    "        freespace_method=FREESPACE_METHOD,\n",
    "        phase_values=INIT_PHASES,\n",
    "        apertures=apertures,\n",
    "        aperture_size=DETECTOR_SIZE\n",
    "    )  # recreate a list of elements\n",
    "\n",
    "    return LinearOpticalSetup(elements=elements_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450c6c03-bd60-4a40-a557-ce3fb0ccd0c6",
   "metadata": {},
   "source": [
    "## 3.2. Detector processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d1e9b5-8703-4201-8743-b54eac91da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_CLASSES = 10  # TODO: how many classes do we have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1dabde-317c-45c3-a9ee-4bffd403b5cb",
   "metadata": {},
   "source": [
    "### 3.2.1. Detector mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c1e018-fb72-480e-b7a4-5eaf29145ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_segment_size = LOADED_VARIABLES['detector_segment_size']  # in neurons (int)\n",
    "detector_segment_size_m = detector_segment_size * NEURON_SIZE  # in [m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ff6e7-d778-4aeb-a6b3-a1d828977f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZONES_ORDER = LOADED_VARIABLES['segments_order']  # TODO: specify the order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb7d86b-ab1d-4575-a757-a8ee00f350dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTOR_MASK_LOADED = torch.load(f'{LOAD_FOLDER}/detector_mask.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b79963c-18c5-4620-82cb-2485a986a1fd",
   "metadata": {},
   "source": [
    "### 3.2.2. Detector processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2adcfd-788b-4939-8471-b87b95c31b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DetectorProcessorOzcanClf object\n",
    "DETECTOR_PROCESSOR = DetectorProcessorClf(\n",
    "    simulation_parameters=SIM_PARAMS,\n",
    "    num_classes=NUMBER_OF_CLASSES,\n",
    "    segmented_detector=DETECTOR_MASK_LOADED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec8806d-73da-4907-ae26-c3622d17553c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2651f63-1063-4b9b-bfb1-b3d0d543babc",
   "metadata": {},
   "source": [
    "#### To visualize detector zones (for further use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6bc396-cfbb-40a0-9bfe-e12987f9e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZONES_HIGHLIGHT_COLOR = 'w'\n",
    "ZONES_LW = 0.5\n",
    "selected_detector_mask = DETECTOR_PROCESSOR.segmented_detector.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd154079-4d24-4787-9304-df43fd2b7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zones_patches(detector_mask):\n",
    "    \"\"\"\n",
    "    Returns a list of patches to draw zones in final visualisation\n",
    "    \"\"\"\n",
    "    zones_patches = []\n",
    "\n",
    "    delta = 0.5\n",
    "    \n",
    "    for ind_class in range(NUMBER_OF_CLASSES):\n",
    "        idx_y, idx_x = (detector_mask == ind_class).nonzero(as_tuple=True)\n",
    "        \n",
    "        zone_rect = patches.Rectangle(\n",
    "            (idx_x[0] - delta, idx_y[0] - delta), \n",
    "            idx_x[-1] - idx_x[0] + 2 * delta, idx_y[-1] - idx_y[0] + 2 * delta, \n",
    "            linewidth=ZONES_LW, \n",
    "            edgecolor=ZONES_HIGHLIGHT_COLOR,\n",
    "            facecolor='none'\n",
    "        )\n",
    "        \n",
    "        zones_patches.append(zone_rect)\n",
    "\n",
    "    return zones_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ec106-878a-4475-bc01-e4b89c8a9280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13e35848-ef9c-4067-9fe0-451df880ca48",
   "metadata": {},
   "source": [
    "# 4. Necessary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c044e0-4da0-461a-bc89-bf46adfd6649",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd9a8b-3e30-44df-8335-099fb140cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bs = LOADED_VARIABLES['train_batch_size']  # a batch size for training set\n",
    "val_bs = LOADED_VARIABLES['val_batch_size']\n",
    "\n",
    "test_bs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4690ed24-c639-47f6-944a-2bca94c98453",
   "metadata": {},
   "source": [
    "#### Train/Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca736b-a938-416e-9362-40c22136c566",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split_seed = LOADED_VARIABLES['train_val_seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaacee1-7361-4d4c-83d6-815ccebaebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_wf_train_ds\n",
    "train_wf_ds, val_wf_ds = torch.utils.data.random_split(\n",
    "    dataset=mnist_wf_train_ds,\n",
    "    lengths=[55000, 5000],  # sizes from the article\n",
    "    generator=torch.Generator().manual_seed(train_val_split_seed)  # for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cdddcf-e93f-4a3c-aebf-bc0be8dd5ca2",
   "metadata": {},
   "source": [
    "#### Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c3fbef-5a00-4784-a5c8-85c47231890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wf_loader = torch.utils.data.DataLoader(\n",
    "    train_wf_ds,\n",
    "    batch_size=train_bs,\n",
    "    shuffle=True,\n",
    "    # num_workers=2,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "val_wf_loader = torch.utils.data.DataLoader(\n",
    "    val_wf_ds,\n",
    "    batch_size=val_bs,\n",
    "    shuffle=False,\n",
    "    # num_workers=2,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_wf_loader = torch.utils.data.DataLoader(\n",
    "    mnist_wf_test_ds,\n",
    "    batch_size=test_bs,\n",
    "    shuffle=False,\n",
    "    # num_workers=2,\n",
    "    drop_last=False,\n",
    ")  # data loader for a test MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a061a7-96a7-44fa-b66b-75a4655f8a5d",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a425d-cff3-44ba-81f6-2fe467c52a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func_clf = nn.CrossEntropyLoss()\n",
    "loss_func_name = 'CE loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09387304-0b69-4b08-b1e4-a1dc5d41890a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb1247c6-9e1c-464c-8f9b-6330c56bfb52",
   "metadata": {},
   "source": [
    "# 5. Load model weights and estimate perfomance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecb3122-ca66-4b28-be8c-7a3bf6d8fb71",
   "metadata": {},
   "source": [
    "## 5.1. Loading of saved results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342eab76-fa52-48f7-a08c-be962e58ef9d",
   "metadata": {},
   "source": [
    "### 5.1.1. Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec8a714-5da7-4a6c-a91a-b05a99902c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_data = np.genfromtxt(\n",
    "    f'{RESULTS_FOLDER}/training_curves.csv',\n",
    "    delimiter=','\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b660e1-c997-438f-bcdd-d28e10ae995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = LOADED_VARIABLES['number_of_epochs']\n",
    "(train_epochs_losses, val_epochs_losses, train_epochs_acc, val_epochs_acc) = losses_data[1:, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628fab74-a031-49a8-abe5-1d2d99f7631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curves plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "axs[0].plot(range(1, NUM_EPOCHS + 1), np.array(train_epochs_losses), label='train')\n",
    "axs[0].plot(range(1, NUM_EPOCHS + 1), np.array(val_epochs_losses), linestyle='dashed', label='validation')\n",
    "\n",
    "axs[1].plot(range(1, NUM_EPOCHS + 1), train_epochs_acc, label='train')\n",
    "axs[1].plot(range(1, NUM_EPOCHS + 1), val_epochs_acc, linestyle='dashed', label='validation')\n",
    "\n",
    "axs[0].set_ylabel(loss_func_name)\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30cbf38-77de-4df0-8094-25be5a19a47e",
   "metadata": {},
   "source": [
    "### 5.1.2. Weights of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de870579-4415-4018-a3f4-ed7fa1d04f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init setup to load weights\n",
    "optical_setup_loaded = get_setup(SIM_PARAMS, LOADED_VARIABLES['use_apertures'])\n",
    "# LOAD WEIGHTS for the model\n",
    "optical_setup_loaded.net.load_state_dict(torch.load(f'{LOAD_FOLDER}/optical_net.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d7330d-a12c-4078-acc7-352cfdfe1df8",
   "metadata": {},
   "source": [
    "### 5.1.3. Trained phase masks visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11683040-3e27-4377-959c-bea12a776875",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = NUM_OF_DIFF_LAYERS  # number of columns for DiffractiveLayer's masks visualization\n",
    "n_rows = 1\n",
    "\n",
    "# plot wavefronts phase\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 3, n_rows * 3.2))\n",
    "ind_diff_layer = 0\n",
    "\n",
    "cmap = 'gist_stern'  # 'gist_stern' 'rainbow'\n",
    "\n",
    "for ind_layer, layer in enumerate(optical_setup_loaded.net):\n",
    "    if isinstance(layer, DiffractiveLayer):  # plot masks for Diffractive layers\n",
    "        if n_rows > 1:\n",
    "            ax_this = axs[ind_diff_layer // n_cols][ind_diff_layer % n_cols]\n",
    "        else:\n",
    "            ax_this = axs[ind_diff_layer % n_cols]\n",
    "\n",
    "        ax_this.set_title(f'{ind_diff_layer + 1}. DiffractiveLayer')\n",
    "\n",
    "        trained_mask = layer.mask.detach()\n",
    "        \n",
    "        ax_this.imshow(         \n",
    "            trained_mask, cmap=cmap,\n",
    "            vmin=0, vmax=MAX_PHASE\n",
    "        )\n",
    "        ind_diff_layer += 1\n",
    "\n",
    "        # select only a part within apertures!\n",
    "        # x_frame = (x_layer_nodes - DETECTOR_SIZE[1]) / 2\n",
    "        # y_frame = (y_layer_nodes - DETECTOR_SIZE[0]) / 2\n",
    "        # ax_this.set_xlim([x_frame, x_layer_nodes - x_frame])\n",
    "        # ax_this.set_ylim([y_frame, y_layer_nodes - y_frame])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6a8c7-c74a-414a-923d-4f080708b8b5",
   "metadata": {},
   "source": [
    "## 5.2. Calculate metrics on test set for the loaded model\n",
    "\n",
    "Checking if the loaded model works correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98333cf9-832f-46ac-8bfa-fef032846a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses_1, _, test_accuracy_1 = onn_validate_clf(\n",
    "    optical_setup_loaded.net,  # optical network with loaded weights\n",
    "    test_wf_loader,  # dataloader of training set\n",
    "    detector_processor,  # detector processor\n",
    "    loss_func_clf,\n",
    "    device=DEVICE,\n",
    "    show_process=True,\n",
    ")  # evaluate the model\n",
    "\n",
    "print(\n",
    "    'Results after training on TEST set:\\n' + \n",
    "    f'\\t{loss_func_name} : {np.mean(test_losses_1):.6f}\\n' +\n",
    "    f'\\tAccuracy : {(test_accuracy_1 * 100):>0.1f} %'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ced0a-7948-4685-bd4e-57ef9e58adfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f47740db-90ff-4b2f-a362-7731a460e768",
   "metadata": {},
   "source": [
    "## 5.3. Example of classification (propagation through the setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba54cc2-d8df-4df5-8aed-08c4f0bd89be",
   "metadata": {},
   "source": [
    "### 5.3.1. Select a sample to propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc4e7e-cfb7-4ed3-9caf-87bc39b7ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot an image\n",
    "# '1' - 3214, good\n",
    "# '4' - 6152, good\n",
    "# '6' - 123, good\n",
    "# '8' - 128, good\n",
    "# '0' - 3, good\n",
    "ind_test = 123\n",
    "cmap = 'hot'\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(2 * 3, 3))\n",
    "\n",
    "test_wavefront, test_target = mnist_wf_test_ds[ind_test]\n",
    "\n",
    "axs[0].set_title(f'intensity (id={ind_test})')\n",
    "axs[0].imshow(test_wavefront.intensity, cmap=cmap)\n",
    "\n",
    "axs[1].set_title(f'phase')\n",
    "axs[1].imshow(\n",
    "    test_wavefront.phase, cmap=cmap,\n",
    "    vmin=0, vmax=2 * torch.pi\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f725f858-61f1-4157-978e-a71403c67701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# propagation of the example through the trained network\n",
    "setup_scheme, test_wavefronts = optical_setup_loaded.stepwise_forward(test_wavefront)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dc20fc-647b-4434-9603-45ff80c09059",
   "metadata": {},
   "source": [
    "### 5.3.2. Detector picture (enlarged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c616ff93-51d4-412d-8475-4cb33954aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure with subplots\n",
    "fig, ax_this = plt.subplots(1, 1, figsize=(3, 3.2))\n",
    "\n",
    "# Detector output (not a wavefront!)\n",
    "ax_this.set_title('Detector Intensity')\n",
    "ax_this.imshow(\n",
    "    test_wavefronts[-1].detach().numpy(), cmap='hot',\n",
    "    # vmin=0, vmax=1  # uncomment to make the same limits\n",
    ")\n",
    "\n",
    "for zone in get_zones_patches(DETECTOR_MASK_LOADED):\n",
    "    # add zone's patches to the axis\n",
    "    ax_this.add_patch(zone)\n",
    "\n",
    "# select only a part within apertures! uncomment if needed\n",
    "# x_frame = (x_layer_nodes - DETECTOR_SIZE[1]) / 2\n",
    "# y_frame = (y_layer_nodes - DETECTOR_SIZE[0]) / 2\n",
    "\n",
    "# plt.axis([x_frame, x_layer_nodes - x_frame, y_layer_nodes - y_frame, y_frame])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392dd721-c8de-4e54-bf55-931c498c4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities of an example classification\n",
    "test_probas = DETECTOR_PROCESSOR.forward(test_wavefronts[-1])\n",
    "# Comment: forward() method is from DetectorProcessorClf\n",
    "#          p_i = I(detector_i) / sum_j(I(detector_j))\n",
    "# Comment: It's another output than for batch_forward, that was used during training!\n",
    "\n",
    "assert np.isclose(test_probas.sum().item(), 1)\n",
    "\n",
    "for label, prob in enumerate(test_probas[0]):\n",
    "    print(f'{label} : {prob * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a24a10-101d-4862-b731-94a6470a0fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5592d4b4-0ea4-456b-9d65-5f56e915ee6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv-local)",
   "language": "python",
   "name": "venv-local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
